{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6161f291-a4cf-4cd0-b0e3-f67ffd3c82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml  # or json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56aea048-460e-4b81-b922-e0da212706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load YAML config file and validate structure.\"\"\"\n",
    "    config_path = Path(config_path)\n",
    "    with open(config_path) as f:\n",
    "        if config_path.suffix == '.yaml':\n",
    "            config = yaml.safe_load(f)\n",
    "        else:\n",
    "            import json\n",
    "            config = json.load(f)\n",
    "    \n",
    "    # Validate config structure\n",
    "    assert \"microdata\" in config, \"Config missing 'microdata' section\"\n",
    "    assert \"constraints\" in config and len(config[\"constraints\"]) > 0, \"No constraints defined\"\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36544bf2-26dd-4b3c-8ff6-ad671e563c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3006ffb3-d570-49e8-87c0-4112a957ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'constraints': [{'constraint_prefix': 's1_hh_urban_rural%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c1_urbanrural_master.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's1_hh_urban_rural',\n",
      "                  'set_as_population_total': True},\n",
      "                 {'constraint_prefix': 's2_hh_size%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c2_hhsize.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's2_hh_size',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's3_hh_tenure_child%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c3_hhtenure_child.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's3_hh_tenure_child',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's4_hh_ncars_hh_size%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c4_hhcars_hhsize.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's4_hh_ncars_hh_size',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's5_hh_beds%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c5_hhbeds.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's5_hh_beds',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's6_hh_heating%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c6_hhheating.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's6_hh_heating',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's7_hh_type%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c7_hhtype.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's7_hh_type',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's8_hhref_activity%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c8_hhref_activity.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's8_hhref_activity',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's9_hhref_sex_hh_size%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c9_hhref_sex_hhsize.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's9_hhref_sex_hh_size',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's10_hhref_ethnicity%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c10_hhref_ethnicity.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's10_hhref_ethnicity',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's11_hhref_age_size_child%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c11_hhref_age_size_child.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's11_hhref_age_size_child',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's12_employment_hh_size%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c12_employment_hh_size.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's12_employment_hh_size',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's13_unpaid_carer%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c13_unpaid_carer.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's13_unpaid_carer',\n",
      "                  'set_as_population_total': False},\n",
      "                 {'constraint_prefix': 's14_deprivation_count%',\n",
      "                  'dataprocess': 'onehot',\n",
      "                  'file': 'data/2025-08-08/data/census2021_c14_deprivation_count.csv',\n",
      "                  'geography_column': 'areacode',\n",
      "                  'microdata_id': 's14_deprivation_count',\n",
      "                  'set_as_population_total': False}],\n",
      " 'microdata': {'file': 'data/2025-08-08/data/us_hh_export.csv',\n",
      "               'id_column': 'hidp'}}\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"data/2025-08-08/data/config.yaml\")\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4b2232-1bf9-4c48-abd6-7afe43d746ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_constraint_arrays(config):\n",
    "    \"\"\"\n",
    "    Enhanced version that:\n",
    "    1. Uses set_as_population_total to calculate population sizes\n",
    "    2. Tracks geography codes (GEOIDs) separately\n",
    "    3. Returns results in a structured dict\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            \"constraint_labels\": List[str],\n",
    "            \"constraint_targets\": np.array,\n",
    "            \"geography_codes\": List[str],\n",
    "            \"population_constraints\": np.array\n",
    "            \"population_totals\":np.arry\n",
    "            \"data_handeling\":List[str]\n",
    "        }\n",
    "    \"\"\"\n",
    "    constraint_labels = []\n",
    "    constraint_targets = None\n",
    "    geography_codes = []\n",
    "    pop_total_constraint = False\n",
    "    population_constraints = []\n",
    "    population_totals=[]\n",
    "    data_handeling=[]\n",
    "    \n",
    "\n",
    "    for constraint in config[\"constraints\"]:\n",
    "        with open(constraint[\"file\"], mode='r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            headers = next(reader)\n",
    "            data = list(reader)\n",
    "        \n",
    "        poptotal_constraint = constraint[\"set_as_population_total\"]\n",
    "        print(poptotal_constraint,constraint[\"file\"])\n",
    "            \n",
    "        geo_col = constraint[\"geography_column\"]\n",
    "        geo_idx = headers.index(geo_col)\n",
    "        \n",
    "        # Store GEOIDs on first pass\n",
    "        if not geography_codes:\n",
    "            geography_codes = [row[geo_idx] for row in data]\n",
    "        \n",
    "        # Handle population totals if specified\n",
    "        if pop_total_constraint: \n",
    "            population_constraints = np.array([float(row[pop_idx]) for row in data])\n",
    "        \n",
    "        # Process categories\n",
    "        categories = [h for i, h in enumerate(headers) if i != geo_idx]\n",
    "        prefix = constraint[\"constraint_prefix\"]\n",
    "        constraint_labels.extend(f\"{prefix}{cat}\" for cat in categories)\n",
    "        \n",
    "        # Extract targets\n",
    "        target_rows = []\n",
    "        for row in data:\n",
    "            target_values = [float(row[i]) for i in range(len(headers)) if i != geo_idx]\n",
    "            total_population = sum(target_values)\n",
    "            if poptotal_constraint:\n",
    "                population_totals.append(total_population)\n",
    "            target_rows.append(target_values)\n",
    "        data_handeling.append(constraint['dataprocess'])\n",
    "\n",
    "        \n",
    "        targets = np.array(target_rows)\n",
    "        constraint_targets = targets if constraint_targets is None else np.hstack([constraint_targets, targets])\n",
    "    \n",
    "    header = ['geography_code','population_total']+constraint_labels\n",
    "    print(header)\n",
    "    print(data_handeling)\n",
    "    table = [[geography_codes[i]]+[population_totals[i]]+constraint_targets[i].tolist() for i in range(len(geography_codes))]\n",
    "    table.insert(0,header)\n",
    "    return {\n",
    "        \"constraint_labels\": constraint_labels,\n",
    "        \"constraint_targets\": constraint_targets.tolist(),\n",
    "        \"geography_codes\": geography_codes,\n",
    "        \"population_totals\":population_totals,\n",
    "        \"data_handeling\":data_handeling,\n",
    "        \"table\":table\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e5001d-8552-4b9b-8a73-0b8749b351b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True data/2025-08-08/data/census2021_c1_urbanrural_master.csv\n",
      "False data/2025-08-08/data/census2021_c2_hhsize.csv\n",
      "False data/2025-08-08/data/census2021_c3_hhtenure_child.csv\n",
      "False data/2025-08-08/data/census2021_c4_hhcars_hhsize.csv\n",
      "False data/2025-08-08/data/census2021_c5_hhbeds.csv\n",
      "False data/2025-08-08/data/census2021_c6_hhheating.csv\n",
      "False data/2025-08-08/data/census2021_c7_hhtype.csv\n",
      "False data/2025-08-08/data/census2021_c8_hhref_activity.csv\n",
      "False data/2025-08-08/data/census2021_c9_hhref_sex_hhsize.csv\n",
      "False data/2025-08-08/data/census2021_c10_hhref_ethnicity.csv\n",
      "False data/2025-08-08/data/census2021_c11_hhref_age_size_child.csv\n",
      "False data/2025-08-08/data/census2021_c12_employment_hh_size.csv\n",
      "False data/2025-08-08/data/census2021_c13_unpaid_carer.csv\n",
      "False data/2025-08-08/data/census2021_c14_deprivation_count.csv\n",
      "['geography_code', 'population_total', 's1_hh_urban_rural%urban', 's1_hh_urban_rural%rural', 's2_hh_size%hhsize_1', 's2_hh_size%hhsize_2', 's2_hh_size%hhsize_3', 's2_hh_size%hhsize_4', 's2_hh_size%hhsize_5', 's2_hh_size%hhsize_6', 's2_hh_size%hhsize_7', 's2_hh_size%hhsize_8', 's3_hh_tenure_child%owned_outright_no_children', 's3_hh_tenure_child%owned_outright_with_children', 's3_hh_tenure_child%owned_mortgage_no_children', 's3_hh_tenure_child%owned_mortgage_with_children', 's3_hh_tenure_child%private_rented_no_children', 's3_hh_tenure_child%private_rented_with_children', 's3_hh_tenure_child%social_rented_no_children', 's3_hh_tenure_child%social_rented_with_children', 's4_hh_ncars_hh_size%hhcars_0_hh_size_1', 's4_hh_ncars_hh_size%hhcars_0_hh_size_2', 's4_hh_ncars_hh_size%hhcars_0_hh_size_3', 's4_hh_ncars_hh_size%hhcars_0_hh_size_4', 's4_hh_ncars_hh_size%hhcars_1_hh_size_1', 's4_hh_ncars_hh_size%hhcars_1_hh_size_2', 's4_hh_ncars_hh_size%hhcars_1_hh_size_3', 's4_hh_ncars_hh_size%hhcars_1_hh_size_4', 's4_hh_ncars_hh_size%hhcars_2_hh_size_1', 's4_hh_ncars_hh_size%hhcars_2_hh_size_2', 's4_hh_ncars_hh_size%hhcars_2_hh_size_3', 's4_hh_ncars_hh_size%hhcars_2_hh_size_4', 's5_hh_beds%hhbeds_1', 's5_hh_beds%hhbeds_2', 's5_hh_beds%hhbeds_3', 's5_hh_beds%hhbeds_4', 's5_hh_beds%hhbeds_5', 's6_hh_heating%with_heating', 's6_hh_heating%without_heating', 's7_hh_type%one_person_household', 's7_hh_type%lone_parent_children', 's7_hh_type%couple_married_civil_no_children', 's7_hh_type%couple_married_civil_with_children', 's7_hh_type%other', 's8_hhref_activity%self_employed', 's8_hhref_activity%in_paid_employment', 's8_hhref_activity%unemployed', 's8_hhref_activity%retired', 's8_hhref_activity%looking_after_home', 's8_hhref_activity%student', 's8_hhref_activity%long_term_sick_disabled', 's8_hhref_activity%other', 's9_hhref_sex_hh_size%hhref_female_hhsize_1', 's9_hhref_sex_hh_size%hhref_female_hhsize_2', 's9_hhref_sex_hh_size%hhref_female_hhsize_3', 's9_hhref_sex_hh_size%hhref_female_hhsize_4', 's9_hhref_sex_hh_size%hhref_male_hhsize_1', 's9_hhref_sex_hh_size%hhref_male_hhsize_2', 's9_hhref_sex_hh_size%hhref_male_hhsize_3', 's9_hhref_sex_hh_size%hhref_male_hhsize_4', 's10_hhref_ethnicity%white', 's10_hhref_ethnicity%mixed', 's10_hhref_ethnicity%asian', 's10_hhref_ethnicity%black_african_caribbean', 's10_hhref_ethnicity%other', 's11_hhref_age_size_child%age_under_34_hhsize_1_no_children', 's11_hhref_age_size_child%age_under_34_hhsize_2_with_children', 's11_hhref_age_size_child%age_under_34_hhsize_2_no_children', 's11_hhref_age_size_child%age_34_54_hhsize_1_no_children', 's11_hhref_age_size_child%age_34_54_hhsize_2_with_children', 's11_hhref_age_size_child%age_34_54_hhsize_2_no_children', 's11_hhref_age_size_child%age_55_65_hhsize_1_no_children', 's11_hhref_age_size_child%age_55_65_hhsize_2_with_children', 's11_hhref_age_size_child%age_55_65_hhsize_2_no_children', 's11_hhref_age_size_child%age_over_66_hhsize_1_no_children', 's11_hhref_age_size_child%age_over_66_hhsize_2_with_children', 's11_hhref_age_size_child%age_over_66_hhsize_2_no_children', 's12_employment_hh_size%employed_0_hh_size_1', 's12_employment_hh_size%employed_1_hh_size_1', 's12_employment_hh_size%employed_0_hh_size_2', 's12_employment_hh_size%employed_1_hh_size_2', 's12_employment_hh_size%employed_2_hh_size_2', 's12_employment_hh_size%employed_0_hh_size_3', 's12_employment_hh_size%employed_1_hh_size_3', 's12_employment_hh_size%employed_2_hh_size_3', 's12_employment_hh_size%employed_3_hh_size_3', 's12_employment_hh_size%employed_0_hh_size_4', 's12_employment_hh_size%employed_1_hh_size_4', 's12_employment_hh_size%employed_2_hh_size_4', 's12_employment_hh_size%employed_3_hh_size_4', 's13_unpaid_carer%carer_0', 's13_unpaid_carer%carer_1', 's13_unpaid_carer%carer_2', 's14_deprivation_count%deprivation_count_0', 's14_deprivation_count%deprivation_count_1', 's14_deprivation_count%deprivation_count_2', 's14_deprivation_count%deprivation_count_3', 's14_deprivation_count%deprivation_count_4']\n",
      "['onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot', 'onehot']\n"
     ]
    }
   ],
   "source": [
    "constraints_dict = build_constraint_arrays(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cbf0f0-07c3-4616-b828-1bada3b1a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_microdata(config, constraint_labels,data_handeling):\n",
    "    \"\"\"\n",
    "    Encode microdata into a one-hot-like array where missing values are 0.\n",
    "    Returns:\n",
    "        microdata_encoded: np.array shape (n_individuals, n_constraints)\n",
    "        ids: list of IDs from the microdata\n",
    "    \"\"\"\n",
    "    # Step 1: Load microdata from CSV\n",
    "    with open(config[\"microdata\"][\"file\"], mode='r') as f:\n",
    "        reader = csv.DictReader(f)  # Reads header and rows as dictionaries\n",
    "        microdata = list(reader)    # Convert to list of dicts\n",
    "\n",
    "    n_individuals = len(microdata)\n",
    "    n_constraints = len(constraint_labels)\n",
    "\n",
    "    # Step 2: Create label-to-index mapping\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(constraint_labels)}\n",
    "\n",
    "    # Step 3: Initialize output array (all zeros)\n",
    "    microdata_encoded = np.zeros((n_individuals, n_constraints), dtype=np.int8)\n",
    "\n",
    "    # Step 4: Extract IDs\n",
    "    ids = [row[config[\"microdata\"][\"id_column\"]] for row in microdata]\n",
    "    \n",
    "\n",
    "    # Step 5: Encode each constraint\n",
    "    for constraint in config[\"constraints\"]:\n",
    "        print(constraint[\"microdata_id\"])\n",
    "        col = constraint[\"microdata_id\"]\n",
    "        prefix = constraint[\"constraint_prefix\"]\n",
    "        dathandling = constraint[\"dataprocess\"]\n",
    "        print(dathandling)\n",
    "        count = 0\n",
    "        count2 = 0\n",
    "        for row_idx, row in enumerate(microdata):\n",
    "            value = row.get(col)  # Get value for the current constraint column\n",
    "            if count%10000 == 0:\n",
    "                print(f\"{count/n_individuals*100:.2g}% complete {count2}  {count} {row_idx}\")\n",
    "            count+=1\n",
    "            # Skip missing values (leave as 0)\n",
    "            if value is not None and value.strip() != '':  # Check for non-empty strings\n",
    "                if dathandling == \"onehot\":\n",
    "                    label = f\"{prefix}{value}\"\n",
    "                    if label in label_to_idx:  # Ensure label exists in constraints\n",
    "                        microdata_encoded[row_idx, label_to_idx[label]]  = 1\n",
    "                else:\n",
    "                    lable=prefix\n",
    "                    if label in label_to_idx:  # Ensure label exists in constraints\n",
    "                        microdata_encoded[row_idx, label_to_idx[label]]  = int(value.strip())\n",
    "                count2+=1                \n",
    "    \n",
    "            table = [[ids[i]] + microdata_encoded[i].tolist() for i in range(len(microdata_encoded))]\n",
    "            # table.insert(0,header)\n",
    "    return {\n",
    "        \"microdata_encoded\":microdata_encoded, \n",
    "        \"ids\":ids,\n",
    "        \"table\":  table\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e3cf36-63cf-4eaf-9836-947d2eb80fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1_hh_urban_rural\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s2_hh_size\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s3_hh_tenure_child\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s4_hh_ncars_hh_size\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s5_hh_beds\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s6_hh_heating\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s7_hh_type\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s8_hhref_activity\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s9_hhref_sex_hh_size\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s10_hhref_ethnicity\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s11_hhref_age_size_child\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s12_employment_hh_size\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s13_unpaid_carer\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n",
      "s14_deprivation_count\n",
      "onehot\n",
      "0% complete 0  0 0\n",
      "51% complete 10000  10000 10000\n"
     ]
    }
   ],
   "source": [
    "microdata_dict = encode_microdata(config,constraints_dict[\"constraint_labels\"],constraints_dict['data_handeling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe2eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(file_path,data):\n",
    "    filename = file_path\n",
    "    # Open the file in write mode\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89d307f-7abd-4225-8861-fdcbab056853",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file('data/england_wales_microdata_encoded_counts_individuals_1808.csv', microdata_dict[\"table\"])\n",
    "to_file('data/england_wales_constraint_targets_counts_individuals_1808.csv', constraints_dict[\"table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cff0ef7-f7ca-4bd6-b764-b46fef812ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e7285-dcb4-45a1-8776-88ff9abc9a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
